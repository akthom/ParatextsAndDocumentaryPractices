<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1460-2059</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">18586735</article-id><article-id pub-id-type="pmc">2718662</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btn187</article-id><article-id pub-id-type="publisher-id">btn187</article-id><article-categories><subj-group subj-group-type="heading"><subject>Ismb 2008 Conference Proceedings 19&#x02013;23 July 2008, Toronto</subject><subj-group><subject>Original Papers</subject><subj-group><subject>Other Bioinformatics Applications and Methods</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>BLASTing small molecules&#x02014;statistics and extreme statistics of chemical similarity scores</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Baldi</surname><given-names>Pierre</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref><xref ref-type="aff" rid="AFF1"><sup>3</sup></xref><xref ref-type="corresp" rid="COR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Benz</surname><given-names>Ryan W.</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref></contrib></contrib-group><aff id="AFF1"><sup>1</sup>Department of Computer Science, <sup>2</sup>Institute for Genomics and Bioinformatics and <sup>3</sup>Department of Biological Chemistry, University of California, Irvine, CA 92697-3435, USA</aff><author-notes><corresp id="COR1">*To whom correspondence should be addressed.</corresp></author-notes><pub-date pub-type="ppub"><day>1</day><month>7</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>1</day><month>7</month><year>2008</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. --><volume>24</volume><issue>13</issue><fpage>i357</fpage><lpage>i365</lpage><permissions><copyright-statement>&#x000a9; 2008 The Author(s)</copyright-statement><copyright-year>2008</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/"><license-p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p><bold>Motivation:</bold> Small organic molecules, from nucleotides and amino acids to metabolites and drugs, play a fundamental role in chemistry, biology and medicine. As databases of small molecules continue to grow and become more open, it is important to develop the tools to search them efficiently. In order to develop a BLAST-like tool for small molecules, one must first understand the statistical behavior of molecular similarity scores.</p><p><bold>Results:</bold> We develop a new detailed theory of molecular similarity scores that can be applied to a variety of molecular representations and similarity measures. For concreteness, we focus on the most widely used measure&#x02014;the Tanimoto measure applied to chem-ical fingerprints. In both the case of empirical fingerprints and fingerprints generated by several stochastic models, we derive accurate approximations for both the distribution and extreme value distribution of similarity scores. These approximation are derived using a ratio of correlated Gaussians approach. The theory enables the calculation of significance scores, such as <italic>Z</italic>-scores and <italic>P</italic>-values, and the estimation of the top hits list size. Empirical results obtained using both the random models and real data from the ChemDB database are given to corroborate the theory and show how it can be applied to mine chemical space.</p><p><bold>Availability:</bold> Data and related resources are available through <ext-link ext-link-type="uri" xlink:href="http://cdb.ics.uci.edu">http://cdb.ics.uci.edu</ext-link></p><p><bold>Contact:</bold> <email>pfbaldi@ics.uci.edu</email></p></abstract></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>1 INTRODUCTION</title><p>Small organic molecules, from nucleotides and amino acids to metabolites and drugs, play a fundamental role in chemistry, biology, and medicine. As chemical repositories of small molecules continue to grow and become more open (Chen <italic>et al.</italic>, <xref ref-type="bibr" rid="B7">2005</xref>, <xref ref-type="bibr" rid="B8">2007</xref>; Irwin and Shoichet, <xref ref-type="bibr" rid="B18">2005</xref>), it becomes increasingly important to develop the tools to search them efficiently. In one of the most typical settings, a query molecule is used to search millions of other compounds not only for exact matches, but also for approximate matches. In a drug discovery project, for instance, one may be interested in retrieving all the commercially-available compounds that are &#x02018;similar&#x02019; to a given lead, with the aim of finding compounds with better physical, chemical, biological or pharmacological properties.</p><p>Likewise, in a reverse synthesis project, one may be interested in identifying small molecules that can explain a mass spectrometry signature, or can be used used as building blocks for the artificial synthesis of a metabolite or a natural product. The idea of searching for molecular &#x02018;cousins&#x02019; is of course not new, and constitutes one of the pillars of bioinformatics where one routinely searches for homologs of nucleotide or amino acid sequences. Search tools such as BLAST (Altschul <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">1997</xref>) and its significance &#x02018;e-scores&#x02019; have become <italic>de facto</italic> standards of modern biology, and have driven the exponential expansion of bioinformatics.</p><p>While molecular similarity is different from molecular homology in that it is not predicated on an underlying evolutionary process, there is no reason to believe that a BLAST-like tool for small molecules cannot be developed. Indeed, many different representations and similarity measures have been developed in chemoinformatics over the years (Leach and Gillet, <xref ref-type="bibr" rid="B20">2005</xref>). Yet no consensus tool such as BLAST has emerged. One of the reasons behind the lack of consensus is that there has been no systematic, large-scale, open study of molecular similarity scores, and their statistical distributions and significance levels. As a result, the majority of existing chemical search engines do not return a score with the molecules they retrieve, let alone any measure of significance. Examples of fundamental questions one would like to address include: What threshold should one use to assess significance in a typical search? Is a Tanimoto score of 0.4 significant or not? How many molecules should be expected to have a score above 0.4 and under which assumptions? How does the answer depend on the size of the database being queried? How does the answer depend on the type of query used? A clear answer to these questions is critical for unifying existing chemical databases and search methods, for assessing the significance of a similarity score, and ultimately for helping to better understand the nature of chemical space.</p><p>Here we address these questions by conducting a systematic statistical study of chemical similarity scores and their extreme values as a function of, for instance, database size. To do so, in <xref ref-type="sec" rid="SEC2">Section 2</xref>, we first define the molecular representations and similarity scores to be used in the study. Then, in <xref ref-type="sec" rid="SEC3">Section 3</xref>, we introduce the probabilistic models required to both approximate empirical distributions of similarity scores and to create random models of the background similarity scores against which significance can be assessed. In <xref ref-type="sec" rid="SEC4">Section 4</xref>, we develop the theory for the distribution of the similarity scores, and in <xref ref-type="sec" rid="SEC5">Section 5</xref> the theory for the distribution of the extreme values of these similarity scores. Experimental results to illustrate and corroborate the theory are described in <xref ref-type="sec" rid="SEC6">Section 6</xref> followed by a discussion and conclusions in <xref ref-type="sec" rid="SEC7">Section 7</xref>.</p></sec><sec id="SEC2"><title>2 MOLECULAR REPRESENTATIONS AND SIMILARITY SCORES</title><p>Many different representations and similarity scores have been developed in chemoinformatics (Leach and Gillet, <xref ref-type="bibr" rid="B20">2005</xref>). The methods to be described are very broadly applicable but, for brevity, we illustrate the theory using one of the most commonly used frameworks across chemoinformatics platforms, namely binary fingerprint representations with Tanimoto similarity scores.</p><sec id="SEC2.1"><title>2.1 Molecular representations: fingerprints</title><p>To search large databases of compounds by similarity, most modern chemoinformatics systems use a fingerprint vector representation (Baldi <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2007</xref>; Fligner <italic>et al.</italic>, <xref ref-type="bibr" rid="B10">2002</xref>; Flower, <xref ref-type="bibr" rid="B11">1998</xref>; James <italic>et al.</italic>, <xref ref-type="bibr" rid="B19">2004</xref>; Leach and Gillet, <xref ref-type="bibr" rid="B20">2005</xref>; Xue <italic>et al.</italic>, <xref ref-type="bibr" rid="B27">2003</xref>, <xref ref-type="bibr" rid="B28">2004</xref>) whereby a molecule is represented by a vector whose components index the presence/absence, or the number of occurrences, of a particular functional group, feature or substructure in the molecular bond graph. Because binary fingerprints are used in the great majority of cases, here we present the theory for these fingerprints, but it should be clear that the theory can readily be adapted to fingerprint based on counts. We use &#x1d49c; to denote a molecule and <inline-formula><inline-graphic xlink:href="btn187i1.jpg"/></inline-formula> to denote the corresponding fingerprint vector. We let <italic>A</italic> denote the number of bits set to 1 (1-bits) in the fingerprint <inline-formula><inline-graphic xlink:href="btn187i2.jpg"/></inline-formula>(<inline-formula><inline-graphic xlink:href="btn187i3.jpg"/></inline-formula>).</p><p>In early chemoinformatics systems, fingerprint vectors were relatively short, containing typically a few dozen components selected from a small set of features, hand-picked by chemists. In most modern systems, however, the major trend is towards the combinatorial construction of extremely long feature vectors with a number of components <italic>N</italic> that can vary in the 10<sup>3</sup>&#x02013;10<sup>6</sup> range, depending on the set of features. Examples of typical features include all possible labeled paths or labeled trees, up to a certain depth. The advantage of these much longer, combinatorially-based representations is 2-fold. First, they do not require expert chemical knowledge, which may be incomplete or unavailable. Second, they can support extremely large numbers of compounds, such as those that are starting to become available in public repositories and commercial catalogs, as well as the recursively enumerable space of virtual molecules (Bohacek <italic>et al.</italic>, <xref ref-type="bibr" rid="B5">1996</xref>). The particular nature of the fingerprint components is not essential for the theory. To illustrate the principles, in the simulations we use both fingerprints based on labeled paths and fingerprints based on labeled shallow trees with qualitatively similar results. For brevity and consistency, the examples reported in the Results are derived primarily using fingerprints based on paths.</p></sec><sec id="SEC2.2"><title>2.2 Fingerprint compression</title><p>In many chemoinformatics systems, the long sparse fingerprint vectors are often compressed to much shorter and denser binary fingerprint vectors. The most widely used method of compression is a lossy compression method based on the application of the logical OR operator to the binary fingerprint vector after modulo wrapping to 1024 bits (James <italic>et al.</italic>, <xref ref-type="bibr" rid="B19">2004</xref>). Thus component <italic>i</italic> of the compressed fingerprint is set to 0 if and only if all the positions <italic>i</italic> modulo 1024 are set to 0 in the uncompressed fingerprint. Other more efficient lossless methods of compression have recently been developed (Baldi <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2007</xref>). With the proper and obvious adjustments, our results are applicable to both lossy compressed and uncompressed fingerprints. Because lossy compressed representations are the most widely used, we report the majority of our results using modulo-OR compressed binary fingerprints of length <italic>N</italic>=1024. Due to their smaller size, these also have the advantage of speeding up Monte Carlo sampling simulations.</p></sec><sec id="SEC2.3"><title>2.3 Similarity scores</title><p>Several similarity measures have been developed for molecular fingerprints (Holliday <italic>et al.,</italic> <xref ref-type="bibr" rid="B17">2002</xref>; Leach and Gillet, <xref ref-type="bibr" rid="B20">2005</xref>; Swamidass and Baldi, <xref ref-type="bibr" rid="B25">2007</xref>). Given two molecules &#x1d49c; and &#x0212c;, the Tanimoto similarity measure is given by
<disp-formula id="M1"><label>(1)</label><graphic xlink:href="btn187m1"/></disp-formula>
Here (<italic>A</italic>&#x02229;<italic>B</italic>) denotes the size of the intersection, i.e. the number of 1-bits common to <inline-formula><inline-graphic xlink:href="btn187i4.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btn187i5.jpg"/></inline-formula>, and <italic>A</italic>&#x0222a;<italic>B</italic> denotes the size of the union, i.e. the number of 1-bits in <inline-formula><inline-graphic xlink:href="btn187i6.jpg"/></inline-formula> or <inline-formula><inline-graphic xlink:href="btn187i7.jpg"/></inline-formula>. Because the Tanimoto similarity is by far the most widely used, the theory and experimental results reported here are based on Tanimoto similarity. However, the same theory can readily be applied to all the other measures. To see this, it suffices to note that the other measures consist of algebraic expressions built from <italic>A</italic>&#x0222a;<italic>B</italic> and <italic>A</italic>&#x02229;<italic>B</italic>, as well as other obvious terms such as <italic>A</italic>, <italic>B</italic>, and sometimes <italic>N</italic>. For instance, the Tversky measure (Rouvray, <xref ref-type="bibr" rid="B24">1992</xref>; Tversky, <xref ref-type="bibr" rid="B26">1977</xref>) is defined as <inline-formula><inline-graphic xlink:href="btn187i8.jpg"/></inline-formula>, where the parameters &#x003b1; and &#x003b2; can be used to tune the search towards the sub-structures or super-structures in the query molecule. The theory to be presented begins precisely by studying the statistical distribution and properties of the intersection and the union, in particular their mean, variance and covariance. Thus, the distribution and statistical properties of all the other similarity measures can readily be derived from the distributions analyzed in this article. For this reason, we focus on the Tanimoto score, which can be viewed as the chemoinformatics analog of the alignment score in bioinformatics.</p></sec><sec id="SEC2.4"><title>2.4 Data</title><p>In the simulations and results, we illustrate the methods using fingerprints of molecules randomly sampled from the &#x0223c;5 M molecules available in the ChemDB database (Chen <italic>et al.</italic>, <xref ref-type="bibr" rid="B7">2005</xref>, <xref ref-type="bibr" rid="B8">2007</xref>), or randomly generated using the stochastic generative models described in <xref ref-type="sec" rid="SEC3">Section 3</xref>. The empirical fingerprints are generated by indexing all the labeled paths of length up to eight, or all the labeled trees of depths up to two present in the molecular bond graph. The labels on the vertices correspond to the atom type (e.g. C, N, O) while the labels on the edges correspond to the bond type (e.g. single, double, triple). The exact details of the fingerprints, which are not important for this study, can be found in (Baldi <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2007</xref>) and references therein. Except where noted, both the empirical and model fingerprints are generated using 1024-bit modulo compression. In the simulations, the reported distributions are typically determined using random samples of <italic>n</italic>=100 query fingerprints against background databases that range in size from 5000 to 1 million fingerprints.</p></sec></sec><sec id="SEC3"><title>3 STATISTICAL MODELS OF FINGERPRINTS</title><p>Statistical models of fingerprints are essential for a variety of tasks. For instance, in fingerprint compression, fingerprints can be viewed as &#x02018;messages&#x02019; produced by a stochastic source and understanding the statistical regularities of the source is essential for deriving efficient compression algorithms that use short codewords for the most frequent events. Here, statistical models are essential in at least two different ways: (1) to model and approximate the distribution of similarity scores; and (2) to assess significance against &#x02018;chance&#x02019;, where chance can be defined in various ways. Similar observations, of course, can be made in sequence analysis to, for instance, assess what is the probability of observing a particular alignment score against a random generative background model of nucleotide or amino acid sequences. It is worth noting that as a default, we assume that the distribution over the queries is the same as the distribution over the molecules in the database. However, these statistical models can also be used to model particular distributions over the space of queries that may differ from the overall distribution.</p><sec id="SEC3.1"><title>3.1 One-parameter Bernoulli trials and binomial model</title><p>The simplest statistical model for binary fingerprints is a sequence of independent identically distributed Bernoulli trials (coin flips) with probability <italic>p</italic> of producing a 1-bit, and <italic>q</italic>=1&#x02212;<italic>p</italic> of producing a 0-bit. This model can be applied to both long fingerprints with a very low <italic>p</italic>, or to the modulo-OR compressed fingerprints of length 1024 with a higher value of <italic>p</italic>. The coin flip model is consistent with fingerprint features that are randomly ordered and statistically exchangeable, in fact even independent, and leads to a binomial model &#x0212c;(<italic>N</italic>, <italic>p</italic>), with only two parameters <italic>N</italic> and <italic>p</italic>, for the total number of 1-bits in the corresponding fingerprints. The Bernoulli/binomial model can be used, either to approximate the distribution of fingerprints in an entire database such as ChemDB, or the distribution of fingerprints given a value for <italic>A</italic> by using <italic>p</italic>=<italic>A</italic>/<italic>N</italic>. In the former case, as we will show (<xref ref-type="fig" rid="F1">Fig. 1</xref>), the binomial model does not reproduce the variance of <italic>A</italic> across the database very well since in a binomial model, the variance <italic>Npq</italic> is always at most equal to the expectation <italic>Np</italic>, whereas in large databases of compounds we tend to observe a larger variance. A better model is a normal distribution &#x1d4a9;(&#x003bc;,&#x003c3;<sup>2</sup>) where the mean &#x003bc;=<italic>Np</italic> and variance &#x003c3;<sup>2</sup>&#x02260;<italic>Npq</italic> are fitted to the empirical distribution across the database. In the latter case, by generating fingerprints with probability <italic>p</italic>=<italic>A</italic>/<italic>N</italic>, the number of 1-bits is not constant and varies around the mean value <italic>A</italic>, introducing some additional variability with respect to the case where <italic>A</italic> is held fixed (<xref ref-type="sec" rid="SEC3.3">Section 3.3</xref>).
<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>Distributions of 1-bits from the ChemDB fingerprints (red &#x02018;+&#x02019;), and the Binomial (blue) and multiple Bernoulli (black) fingerprint models. The empirical distribution was also fit to a Gaussian (yellow), which approximates the data well. While the model distribution means are close to the empirical mean, the distribution widths are significantly smaller.</p></caption><graphic xlink:href="btn187f1"/></fig>
</p></sec><sec id="SEC3.2"><title>3.2 Multiple-parameter Bernoulli model</title><p>While the coin flip model is useful to derive a number of approximations, it is clear that chemical fingerprints have a more complex structure and their components are not exactly exchangeable since the individual feature probabilities <italic>p</italic><sub>1</sub>,&#x02026;,<italic>p</italic><sub><italic>N</italic></sub> are not identical and equal to <italic>p</italic> but vary and, when reordered in decreasing order, follow roughly a power-law distribution (Baldi <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2007</xref>), especially in the uncompressed case. The probability of the <italic>j</italic>-ranked component is given approximately by <italic>p</italic><sub><italic>j</italic></sub>=<italic>Cj</italic><sup>&#x02212;&#x003b1;</sup> resulting in a line with slope &#x02212;&#x003b1; in a log-log plot. Thus, the statistical model at the next level of approximation is that of a sequence of non-stationary coin flips where the probability <italic>p</italic><sub><italic>j</italic></sub> of each coin flip varies. The multiple-parameter Bernoulli model has <italic>N</italic> parameters: <italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, &#x02026;, and <italic>p</italic><sub><italic>N</italic></sub>. In this case, the expectation of the total number <italic>A</italic> of 1-bits is given by &#x02211;<sub><italic>i</italic></sub><italic>p</italic><sub><italic>i</italic></sub> and its variance by <inline-formula><inline-graphic xlink:href="btn187i9.jpg"/></inline-formula>. This model is useful in simulations and compression (Baldi <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2007</xref>), but cannot be treated analytically due to its large number of parameters, unless the approximation <italic>p</italic><sub><italic>j</italic></sub>=<italic>Cj</italic><sup>&#x02212;&#x003b1;</sup> is used. A distribution over queries different from the overall distribution could be modeled using a multiple-parameter Bernoulli model with different parameters <italic>r</italic><sub>1</sub>, &#x02026;, <italic>r</italic><sub><italic>N</italic></sub>.</p></sec><sec id="SEC3.3"><title>3.3 Conditional distribution model</title><p>Both the binomial and multiple-parameter Bernoulli models consider the fingerprint components as independent random variables. The conditional distribution model is an exchangeable model where the components are weakly coupled. To generate a fingerprint vector under this model, we first sample <italic>A</italic>, the total number of 1-bits, using a given distribution, typically a Gaussian. Then we sample uniformly over fingerprint vectors containing <italic>A</italic> 1-bits (which can be realized by randomly permuting the components of real fingerprints). The conditional Gaussian model has only three parameters: the mean &#x003bc;, the variance &#x003c3;<sup>2</sup> and <italic>N</italic>. Compared to the binomial model, the additional parameter in the conditional Gaussian model allows for a better fit of the variance of <italic>A</italic> in the data.</p></sec><sec id="SEC3.4"><title>3.4 Spin model</title><p>More complex, second order, models are possible but will not be considered here. These models are essentially spin models from statistical physics, and are also known as Markov random fields or Boltzmann machines (Ackley <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">1985</xref>; Frey, <xref ref-type="bibr" rid="B12">1998</xref>). In these models, one would have to also take into account the correlations between pairs of features which can be superimposed over the multiple Bernoulli model. In real data, these correlations are not exchangeable, and thus behave differently from those introduced in the conditional distribution model. In real data, however, and especially in the case of uncompressed fingerprints, these correlations are close to 0 both on average and in the typical case, and will not be considered here any further. In general, these models cannot be treated exactly.</p></sec></sec><sec id="SEC4"><title>4 THEORY: SIMILARITY SCORE DISTRIBUTION</title><p>As we have seen, most similarity measures between two fingerprints are built by first computing the intersection and the union. Thus, the basic strategy, is to first study the distribution of the intersection and the union under some of the statistical models given above. Note that the intersection and union, in general, are not two independent random variables, but have a non-zero correlation that must be estimated. Knowledge of the distributions of the intersection and unions can then be used to study the Tanimoto measure and derive its approximate distribution under various assumptions.</p><sec id="SEC4.1"><title>4.1 Single-parameter Bernoulli/binomial model</title><p>Under the exchangeable independent model, molecules <italic>B</italic> in the database can be modeled by a binomial &#x0212c;(<italic>N</italic>,<italic>p</italic>) which can be approximated by a normal distribution &#x1d4a9;(<italic>Np</italic>, <italic>Npq</italic>) for large <italic>N</italic>. Consider a query <italic>A</italic> with distribution &#x0212c;(<italic>N</italic>,<italic>r</italic>) which can be approximated by &#x1d4a9;(<italic>Nr</italic>, <italic>Nrs</italic>) (<italic>s</italic>=1&#x02212;<italic>r</italic>) for large <italic>N</italic>. Then the intersection <italic>I</italic>=<italic>A</italic>&#x02229;<italic>B</italic>=&#x02211;<sub><italic>i</italic></sub><italic>I</italic><sub><italic>i</italic></sub>=&#x02211;<sub><italic>i</italic></sub>(<italic>A</italic><sub><italic>i</italic></sub>&#x02229;<italic>B</italic><sub><italic>i</italic></sub>) is a random variable with binomial distribution &#x0212c;(<italic>N</italic>, <italic>pr</italic>), which can be approximated by a normal distribution &#x1d4a9;(<italic>Npr</italic>, <italic>Npr</italic>(1&#x02212;<italic>pr</italic>)) for large <italic>N</italic>, as well as a Poisson distribution &#x1d4ab;(<italic>Npr</italic>) when <italic>N</italic> is large and <italic>pr</italic> is very small. Then the union <italic>U</italic>=<italic>A</italic>&#x0222a;<italic>B</italic>=&#x02211;<sub><italic>i</italic></sub><italic>U</italic><sub><italic>i</italic></sub>=&#x02211;<sub><italic>i</italic></sub> (<italic>A</italic><sub><italic>i</italic></sub>&#x0222a;<italic>B</italic><sub><italic>i</italic></sub>) is a random variable with binomial distribution &#x0212c;(<italic>N</italic>,1&#x02212;<italic>qs</italic>)=&#x0212c;(<italic>N</italic>,<italic>p</italic>+<italic>r</italic>&#x02212;<italic>pr</italic>), which can be approximated by a normal distribution &#x1d4a9;(<italic>N</italic>(1&#x02212;<italic>qs</italic>), <italic>N</italic>(1&#x02212;<italic>qs</italic>)<italic>qs</italic>) for large <italic>N</italic>, and a Poisson distribution &#x1d4ab;(<italic>N</italic>(<italic>p</italic>+<italic>r</italic>&#x02212;<italic>pr</italic>)) when <italic>N</italic> is large and <italic>p</italic>+<italic>r</italic>&#x02212;<italic>pr</italic> is small.</p><p>Under the binomial model, we can get an exact expression for the distribution of the Tanimoto scores. Note that the Tanimoto score <italic>T</italic>=<italic>I</italic>/<italic>U</italic> can only take rational values <italic>t</italic> between 0 and 1. Assuming that <italic>n</italic> and <italic>m</italic> are irreducible, with 0&#x02264;<italic>n</italic>&#x02264;<italic>m</italic> and <italic>t</italic>=<italic>n</italic>/<italic>m</italic>, the probability <italic>P</italic>(<italic>T</italic>=<italic>t</italic>) is given exactly by
<disp-formula id="M2"><label>(2)</label><graphic xlink:href="btn187m2"/></disp-formula>
where <italic>K</italic> is the largest integer such that <italic>Km</italic>&#x02264;<italic>N</italic>, i.e. <inline-formula><inline-graphic xlink:href="btn187i10.jpg"/></inline-formula>. Clearly if <italic>t</italic> is not rational, this probability is 0. Thus, in principle, from this distribution we can derive all the properties of the score distribution, including its mean and variance, under the assumptions of the binomial model.</p><p>In practice, it is easier to approximate the numerator <italic>I</italic> and denominator <italic>U</italic> by Gaussian distributions and view the Tanimoto score as the ratio of two correlated Gaussians. Thus, we next need to compute the covariance between <italic>I</italic> and <italic>U</italic> under the binomial model. Noticing that <italic>I</italic><sub><italic>i</italic></sub> and <italic>U</italic><sub><italic>j</italic></sub> are independent for <italic>i</italic>&#x02260;<italic>j</italic>, we have
<disp-formula id="M3"><label>(3)</label><graphic xlink:href="btn187m3"/></disp-formula>
A direct calculation gives Cov(<italic>I</italic><sub><italic>i</italic></sub>,<italic>U</italic><sub><italic>i</italic></sub>)=<italic>E</italic>(<italic>I</italic><sub><italic>i</italic></sub><italic>U</italic><sub><italic>i</italic></sub>)&#x02212;<italic>E</italic>(<italic>I</italic><sub><italic>i</italic></sub>)<italic>E</italic>(<italic>U</italic><sub><italic>i</italic></sub>)=<italic>pr</italic>(1&#x02212;<italic>p</italic>&#x02212;<italic>r</italic>+<italic>pr</italic>) so that
<disp-formula id="M4"><label>(4)</label><graphic xlink:href="btn187m4"/></disp-formula></p></sec><sec id="SEC4.2"><title>4.2 Multiple-parameter Bernoulli model</title><p>The analysis above for the binomial model can easily be extended to the multiple-parameter Bernoulli model by using similar expressions for the mean, variance and covariance of the individual variables <italic>I</italic><sub><italic>i</italic></sub> and <italic>U</italic><sub><italic>i</italic></sub>, and combining them using the linearity of the expectation and the independence of components associated with different indices. In this case, we let <italic>p</italic><sub>1</sub>,<italic>p</italic><sub>2</sub>,&#x02026; ,<italic>p</italic><sub><italic>N</italic></sub> be the vector of probabilities for the database and <italic>r</italic><sub>1</sub>,<italic>r</italic><sub>2</sub>,&#x02026;,<italic>r</italic><sub><italic>N</italic></sub> the vector of probabilities for the queries. The mean and variance of <italic>I</italic> are given by &#x02211;<sub><italic>i</italic></sub><italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub> and &#x02211;<sub><italic>i</italic></sub><italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>(1&#x02212;<italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>), respectively. Thus, <italic>I</italic> can be approximated by a normal distribution &#x1d4a9;(&#x02211;<sub><italic>i</italic></sub><italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>,&#x02211;<sub><italic>i</italic></sub><italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>(1&#x02212;<italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>)). Likewise, the mean and variance of <italic>U</italic> are given by &#x02211;<sub><italic>i</italic></sub> (1&#x02212;<italic>q</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>i</italic></sub>) and &#x02211;<sub><italic>i</italic></sub> (1&#x02212;<italic>q</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>i</italic></sub>)<italic>q</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>i</italic></sub>, respectively. Thus, <italic>U</italic> can be approximated by a normal distribution &#x1d4a9;(&#x02211;<sub><italic>i</italic></sub> (1&#x02212;<italic>q</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>i</italic></sub>),&#x02211;<sub><italic>i</italic></sub> (1&#x02212;<italic>q</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>i</italic></sub>)<italic>q</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>i</italic></sub>). Finally, for the individual covariance terms we have Cov(<italic>I</italic><sub><italic>i</italic></sub>,<italic>U</italic><sub><italic>i</italic></sub>)=<italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>(1&#x02212;<italic>p</italic><sub><italic>i</italic></sub>&#x02212;<italic>r</italic><sub><italic>i</italic></sub>+<italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>) and Cov(<italic>I</italic><sub><italic>i</italic></sub>,<italic>U</italic><sub><italic>j</italic></sub>)=0 for <italic>i</italic>&#x02260;<italic>j</italic>. Therefore, the full covariance is given by the sum Cov(<italic>I</italic>,<italic>U</italic>)=&#x02211;<sub><italic>i</italic></sub><italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>(1&#x02212;<italic>p</italic><sub><italic>i</italic></sub>&#x02212;<italic>r</italic><sub><italic>i</italic></sub>+<italic>p</italic><sub><italic>i</italic></sub><italic>r</italic><sub><italic>i</italic></sub>).</p></sec><sec id="SEC4.3"><title>4.3 Conditional Gaussian model and hypergeometric distribution</title><p>In some cases, it is useful to condition the Tanimoto scores on a fixed value of <italic>A</italic>. For example, when <italic>A</italic> is very small or very large, the Tanimoto distribution may differ from that for an average query, and a better approximation may be obtained by conditioning the distribution on <italic>A</italic>. The binomial model &#x0212c;(<italic>N</italic>, <italic>r</italic>=<italic>A</italic>/<italic>N</italic>) is not an ideal model since it introduces additional fluctuations on the value <italic>A</italic>. To address this issue, under the exchangeable hypothesis (no need for independence), it is easy to see that for fixed <italic>A</italic> and <italic>B</italic> the intersection <italic>I</italic>=<italic>A</italic>&#x02229;<italic>B</italic> has a hypergeometric distribution with probabilities given by
<disp-formula id="M5"><label>(5)</label><graphic xlink:href="btn187m5"/></disp-formula>
for <italic>A</italic>+<italic>B</italic>&#x02212;<italic>N</italic>&#x02264;<italic>k</italic>&#x02264;inf(<italic>A</italic>, <italic>B</italic>), and 0 otherwise. The mean and variance of the hypergeometric distribution are given by <italic>AB</italic>/<italic>N</italic> and <italic>AB</italic>(<italic>N</italic>&#x02212;<italic>A</italic>)(<italic>N</italic>&#x02212;<italic>B</italic>)/<italic>N</italic><sup>2</sup>(<italic>N</italic>&#x02212;1). The union can be studied from the intersection by writing <italic>U</italic>=<italic>A</italic>+<italic>B</italic>&#x02212;<italic>I</italic>, so that <italic>P</italic>(<italic>U</italic>=<italic>k</italic>|<italic>A</italic>,<italic>B</italic>)=<italic>P</italic>(<italic>I</italic>=<italic>A</italic>+<italic>B</italic>&#x02212;<italic>k</italic>|<italic>A</italic>,<italic>B</italic>). Thus, when <italic>A</italic> and <italic>B</italic> are fixed, we have <italic>E</italic>(<italic>U</italic>)=<italic>A</italic>+<italic>B</italic>&#x02212;<italic>E</italic>(<italic>I</italic>), Var(<italic>U</italic>)=Var(<italic>I</italic>), and Cov(<italic>I</italic>,<italic>U</italic>)=&#x02212;Var(<italic>I</italic>).</p><p>To study the Tanimoto scores directly, we have the conditional density
<disp-formula id="M6"><label>(6)</label><graphic xlink:href="btn187m6"/></disp-formula>
and conditional cumulative distribution
<disp-formula id="M7"><label>(7)</label><graphic xlink:href="btn187m7"/></disp-formula>
Therefore, the probability distribution for the similarity <italic>T</italic> can be derived from the hypergeometric distribution of <italic>I</italic>, given <italic>A</italic>, <italic>B</italic> and <italic>N</italic>. In particular, we have the conditional distribution
<disp-formula id="M8"><label>(8)</label><graphic xlink:href="btn187m8"/></disp-formula>
where the sum is over the distribution <italic>P</italic>(<italic>B</italic>). To model this distribution, we can use the binomial model <inline-formula><inline-graphic xlink:href="btn187i11.jpg"/></inline-formula>. But it is often preferable, as previously discussed, to use a more flexible Gaussian model with
<disp-formula id="M9"><label>(9)</label><graphic xlink:href="btn187m9"/></disp-formula>
where the mean and standard deviation are fitted to the empirical values. The unconditional distribution of Tanimoto scores is given by a second integration over the distribution <italic>P</italic>(<italic>A</italic>) of queries
<disp-formula id="M10"><label>(10)</label><graphic xlink:href="btn187m10"/></disp-formula></p><p>Again, for convenience, we will assume that <italic>P</italic>(<italic>A</italic>)=<italic>P</italic>(<italic>B</italic>) as a default, i.e. we will use the same distribution for the queries and the molecules in the database, but in specific applications this does not have to be so. Below, we refer to this unconditional model with <italic>P</italic>(<italic>A</italic>)=<italic>P</italic>(<italic>B</italic>) represented as Gaussians as the hypergeometric/Gaussian model.</p></sec><sec id="SEC4.4"><title>4.4 Ratio-of-Gaussians approximation</title><p>Whether one uses the binomial, multiple Bernoulli or hyper-geometric models, or the empirical data, in the end, the Tanimoto score distribution can be approximated by the distribution of the ratio-of-correlated Gaussians approximating the numerator and the denominator, respectively. The different models will yield different estimates of the mean, variance and covariance of the Gaussians. Note that the same approach can be used to approximate directly the empirical distribution of the Tanimoto scores in a database such as ChemDB. The only difference is that instead of fitting the correlated Gaussian parameters to the intersection and union distributions under a probabilistic model, we fit the parameters to the empirical intersection and union distributions in ChemDB.</p><p>The density of the ratio of correlated Gaussian distributions can be obtained analytically, although its expression is somewhat involved (Cedilnik <italic>et al.</italic>, <xref ref-type="bibr" rid="B6">2004</xref>; Hinkley, <xref ref-type="bibr" rid="B16">1969</xref>; Marsaglia, <xref ref-type="bibr" rid="B22">1965</xref>; Pham-Gia <italic>et al.</italic>, <xref ref-type="bibr" rid="B23">2006</xref>). The probability density for <italic>T</italic>=<italic>X</italic>/<italic>Y</italic>, where <inline-formula><inline-graphic xlink:href="btn187i12.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="btn187i13.jpg"/></inline-formula>, and &#x003c1;=Corr(<italic>X</italic>,<italic>Y</italic>)&#x02260;&#x000b1;1 is given by the product of two terms
<disp-formula id="M11"><label>(11)</label><graphic xlink:href="btn187m11"/></disp-formula>
or
<disp-formula id="M12"><label>(12)</label><graphic xlink:href="btn187m12"/></disp-formula>
where
<disp-formula id="M13"><label>(13)</label><graphic xlink:href="btn187m13"/></disp-formula>
<disp-formula id="M14"><label>(14)</label><graphic xlink:href="btn187m14"/></disp-formula>
and
<disp-formula id="M15"><label>(15)</label><graphic xlink:href="btn187m15"/></disp-formula>
Thus, anytime we can approximate the distribution of the intersection and the union by two correlated Normal distributions, the distribution of the Tanimoto scores can be approximated using Equations (<xref ref-type="disp-formula" rid="M11">11</xref>)&#x02013;(<xref ref-type="disp-formula" rid="M15">15</xref>) with <italic>X</italic>=<italic>I</italic> and <italic>Y</italic>=<italic>U</italic>. This approach can be used, for instance, to derive the mean and standard deviation of the Tanimoto scores under various assumptions including: (1) the binomial and multiple-parameter Bernoulli models with <italic>p</italic>=<italic>r</italic> (or <italic>p</italic><sub><italic>i</italic></sub>=<italic>r</italic><sub><italic>i</italic></sub>) for the average Tanimoto scores across all queries; (2) the binomial and multiple-parameter Bernoulli models with <italic>p</italic>&#x02260;<italic>r</italic> (or <italic>p</italic><sub><italic>i</italic></sub>&#x02260;<italic>r</italic><sub><italic>i</italic></sub>) for queries modeled by a different Bernoulli model than the one used for the database being searched; (3) the hypergeometric model with <italic>A</italic> fixed, or <italic>A</italic> integrated over the database distribution, or a distribution over queries; and (4) the empirically-derived Gaussian models for the union and intersection averaged over the entire database, or focused on a particular class of molecules. Finally, from the ratio of Gaussians approximation of the score distribution, it is possible to estimate the number of molecules that have a score greater than or equal to <italic>t</italic>.</p></sec></sec><sec id="SEC5"><title>5 THEORY: SIGNIFICANCE, <italic>Z</italic>-SCORES, EXTREME VALUE DISTRIBUTIONS, AND <italic>P</italic>-VALUES</title><p>There are at least two basic approaches for detecting when a similarity score is significant: <italic>Z</italic>-scores, and <italic>P</italic>-values associated with the extreme value distributions.</p><sec id="SEC5.1"><title>5.1 <italic>Z</italic>-scores</title><p>In the <italic>Z</italic>-score approach, one simply looks at the distance of a score from the mean of the scores, in numbers of standard deviations. Therefore, the <italic>Z</italic>-score is given by
<disp-formula id="M16"><label>(16)</label><graphic xlink:href="btn187m16"/></disp-formula>
The parameters &#x003bc; and &#x003c3; can be determined either empirically from a database of fingerprints, or using the statistical models described above. While <italic>Z</italic>-scores can be useful, their focus is on the mean and standard deviation of the distribution of the scores, not on the tail of extreme values.</p></sec><sec id="SEC5.2"><title>5.2 Extreme value distributions and <italic>P</italic>-values</title><p>The second approach is to compute <italic>P</italic>-values. For a given score <italic>t</italic>, its <italic>P</italic>-value is the probability of finding a score equal or greater to <italic>t</italic> under a random model. Thus in this case, one is interested in modeling the tail of the distribution of the scores, and more precisely the distribution of the maximum score (Coles, <xref ref-type="bibr" rid="B9">2001</xref>; Galambos <xref ref-type="bibr" rid="B13">1978</xref>; Leadbetter <italic>et al.</italic>, <xref ref-type="bibr" rid="B21">1983</xref>). This distribution depends on the size of the database being searched since for a given query, and everything else being equal, we can expect the maximum similarity value to increase with the database size.</p><p>Consider a query molecule &#x1d49c; and a database containing <italic>D</italic> molecules, yielding <italic>D</italic> similarity scores <italic>t</italic><sub>1</sub>,&#x02026;,<italic>t</italic><sub><italic>D</italic></sub>. The cumulative distribution of the maximum <italic>F</italic><sub>max</sub>(<italic>t</italic>)=<italic>P</italic>(max&#x02264;<italic>t</italic>) is given by
<disp-formula id="M17"><label>(17)</label><graphic xlink:href="btn187m17"/></disp-formula>
under the usual assumption that the scores are independent and identically distributed. Here <italic>F</italic><sub><italic>T</italic></sub>(<italic>t</italic>) is the cumulative distribution of a single score. A <italic>P</italic>-value is obtained by computing the probability <italic>p</italic>=1&#x02212;<italic>F</italic><sub>max</sub>(<italic>t</italic>) that the maximum score is larger than <italic>t</italic> under a chance model.</p><p>The density of the maximum is obtained by differentiation
<disp-formula id="M18"><label>(18)</label><graphic xlink:href="btn187m18"/></disp-formula>
where <italic>f</italic><sub><italic>T</italic></sub>(<italic>t</italic>) is the density of a single score. In the case of Tanimoto similarity scores, <italic>f</italic><sub><italic>T</italic></sub>(<italic>t</italic>) can be approximated by the ratio-of-Gaussians approach described above, and <italic>F</italic><sub><italic>T</italic></sub>(<italic>t</italic>) is obtained from <italic>f</italic><sub><italic>T</italic></sub>(<italic>t</italic>) by integration. <italic>F</italic><sub><italic>T</italic></sub>(<italic>t</italic>) can also be approximated by (Hinkley, <xref ref-type="bibr" rid="B16">1969</xref>)
<disp-formula id="M19"><label>(19)</label><graphic xlink:href="btn187m19"/></disp-formula>
where <inline-formula><inline-graphic xlink:href="btn187i14.jpg"/></inline-formula> is the cumulative distribution of the normalized Gaussian distribution. This approximation is good when the denominator of the ratio-of-Gaussians is positive, with its standard deviation much larger than its average. By combining Equations (<xref ref-type="disp-formula" rid="M11">11</xref>), (<xref ref-type="disp-formula" rid="M18">18</xref>) and (<xref ref-type="disp-formula" rid="M19">19</xref>), we get:
<disp-formula id="M20"><label>(20)</label><graphic xlink:href="btn187m20"/></disp-formula></p><p>Finally, because the Tanimoto scores are bounded by one, the theory of extreme value distributions shows that the cumulative distribution of the normalized maximum score <italic>n</italic><sub><italic>D</italic></sub>, normalized linearly in the form <italic>n</italic><sub><italic>D</italic></sub>=<italic>a</italic><sub><italic>D</italic></sub>max+<italic>b</italic><sub><italic>D</italic></sub> using appropriate sequences <italic>a</italic><sub><italic>D</italic></sub> and <italic>b</italic><sub><italic>D</italic></sub> of normalizing constants, converges to a type-III extreme value distribution, or Weibull distribution function, of the form
<disp-formula id="M21"><label>(21)</label><graphic xlink:href="btn187m21"/></disp-formula></p></sec></sec><sec id="SEC6"><title>6 EXPERIMENTAL RESULTS</title><sec id="SEC6.1"><title>6.1 Distributions of <italic>A</italic>, <italic>A</italic>&#x02229;<italic>B</italic> and <italic>A</italic>&#x0222a;<italic>B</italic></title><p>In this section we investigate the distributions of the number of fingerprint bits set to 1 per molecule (1-bits), as well as the intersection and union distributions, using empirical fingerprints extracted from ChemDB and the fingerprint models described in <xref ref-type="sec" rid="SEC3">Section 3</xref>. <xref ref-type="fig" rid="F1">Figure 1</xref> compares the empirical 1-bit distribution to the distributions arising from the binomial and multiple parameter Bernoulli models. The two model distributions are similar, and match the empirical distribution mean, but not the variance, which is larger for the empirical fingerprints due to the diversity of molecule sizes in the database. Similar results are also observed for the intersection and union distributions (<xref ref-type="fig" rid="F2">Fig. 2</xref>), where the binomial and multiple Bernoulli models provide a good approximation of the distribution means, but have much smaller standard deviations. To better model the width of the empirical distributions, the hypergeometric model is used in conjunction with a Gaussian distribution to describe the underlying fingerprints. As discussed in <xref ref-type="sec" rid="SEC4.3">Section 4.3</xref> and apparent from <xref ref-type="fig" rid="F1">Figure 1</xref>, a more flexible Gaussian model accurately describes the empirical fingerprint distribution. Under the hypergeometric model, the intersection and union distributions are determined by integrating Equation (<xref ref-type="disp-formula" rid="M5">5</xref>), and its union analog, over <italic>P</italic>(<italic>A</italic>) and <italic>P</italic>(<italic>B</italic>) modeled by the same Gaussian distribution fit to the empirical 1-bit distribution. Compared to the binomial and multiple Bernoulli distributions, the hypergeometric/Gaussian distributions are much wider, and are very similar to those observed empirically (<xref ref-type="fig" rid="F2">Fig. 2</xref>). In all cases, the distributions are well approximated by Gaussians, with &#x003c7;<sup>2</sup> values in the 10<sup>&#x02212;4</sup>&#x02013;10<sup>&#x02212;6</sup> range (see <xref ref-type="table" rid="T1">Table 1</xref> for parameters), though deviations are seen in the tails of the distributions for the empirical results.
<fig id="F2" position="float"><label>Fig. 2.</label><caption><p>Intersection (red) and union (blue) distributions calculated empirically from the ChemDB fingerprints, and from the various fingerprint models described above. For the ChemDB results, the distributions were empirically sampled (&#x02018;+&#x02019;), and fit to Gaussians (solid lines). The calculated hypergeometric/Gaussian distributions are shown with &#x02018;+&#x02019; symbols, and the Gaussian fits in solid lines, which are good approximations of the empirical distributions. In the case of the binomial and multiple Bernoulli models, the Gaussian approximations are shown (solid lines), which can be calculated directly from the model parameters. In all cases, the distributions are well approximated by Gaussian distributions.</p></caption><graphic xlink:href="btn187f2"/></fig>
<table-wrap id="T1" position="float"><label>Table 1.</label><caption><p>Distribution parameters of Gaussian approximations for the 1-bit, intersection, and union distributions</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="left" rowspan="1" colspan="1">Distribution</th><th align="left" rowspan="1" colspan="1"><bold>&#x003bc;</bold></th><th align="left" rowspan="1" colspan="1"><bold>&#x003c3;</bold></th></tr></thead><tbody><tr><td rowspan="1" colspan="1">1-Bits (ChemDB)</td><td rowspan="1" colspan="1">205.8</td><td rowspan="1" colspan="1">97.9</td></tr><tr><td rowspan="1" colspan="1">1-Bits (Binomial)</td><td rowspan="1" colspan="1">215.0</td><td rowspan="1" colspan="1">13.0</td></tr><tr><td rowspan="1" colspan="1">1-Bits (Multiple Bernoulli)</td><td rowspan="1" colspan="1">217.7</td><td rowspan="1" colspan="1">12.3</td></tr><tr><td rowspan="1" colspan="1">Intersection (ChemDB)</td><td rowspan="1" colspan="1">58.2</td><td rowspan="1" colspan="1">31.3</td></tr><tr><td rowspan="1" colspan="1">Intersection (Binomial)</td><td rowspan="1" colspan="1">45.1</td><td rowspan="1" colspan="1">6.6</td></tr><tr><td rowspan="1" colspan="1">Intersection (Multiple Bernoulli)</td><td rowspan="1" colspan="1">66.4</td><td rowspan="1" colspan="1">6.9</td></tr><tr><td rowspan="1" colspan="1">Intersection (Hypergeometric/Gaussian)</td><td rowspan="1" colspan="1">31.2</td><td rowspan="1" colspan="1">31.8</td></tr><tr><td rowspan="1" colspan="1">Union (ChemDB)</td><td rowspan="1" colspan="1">364.7</td><td rowspan="1" colspan="1">109.0</td></tr><tr><td rowspan="1" colspan="1">Union (Binomial)</td><td rowspan="1" colspan="1">385.7</td><td rowspan="1" colspan="1">15.8</td></tr><tr><td rowspan="1" colspan="1">Union (Multiple Bernoulli)</td><td rowspan="1" colspan="1">369.1</td><td rowspan="1" colspan="1">14.3</td></tr><tr><td rowspan="1" colspan="1">Union (Hypergeometric/Gaussian)</td><td rowspan="1" colspan="1">380.5</td><td rowspan="1" colspan="1">107.2</td></tr></tbody></table><table-wrap-foot><fn><p>The ChemDB parameters were obtained from Gaussian fits of the sampled distributions. The binomial and multiple Bernoulli parameters were calculated directly from the models, and the hypergeometric/Gaussian parameters were obtained from Gaussian fits to the distribution calculated directly from the equations in <xref ref-type="sec" rid="SEC4.3">Section 4.3</xref>.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="SEC6.2"><title>6.2 Ratio-of-Gaussians</title><p>From the Gaussian approximations of the intersection and union distributions, determined either empirically or from the fingerprint models, it is possible to model the Tanimoto score distribution as a ratio-of-correlated Gaussians. To test how well this model works in practice, the Tanimoto distributions are first sampled using empirical ChemDB fingerprints, and randomly generated fingerprints under the binomial and multiple Bernoulli models. The Tanimoto distribution for the hypergeometric/Gaussian model is calculated directly from Equation (<xref ref-type="disp-formula" rid="M10">10</xref>). Next, the corresponding ratio-of-Gaussians approximations, <italic>f</italic><sub><italic>T</italic></sub>(<italic>t</italic>), are calculated according to Equation (<xref ref-type="disp-formula" rid="M12">12</xref>) using the intersection and union parameters given in <xref ref-type="table" rid="T1">Table 1</xref>, along with the intersection and union correlations, calculated empirically for the ChemDB and hypergeometric/Gaussian results, and analytically for the binomial and multiple Bernoulli models (<xref ref-type="table" rid="T2">Table 2</xref>). In each case, the ratio-of-Gaussians model provides a good approximation of the observed Tanimoto distributions (<xref ref-type="fig" rid="F3">Fig. 3</xref>). Therefore, as these results show, it is possible to accurately predict the distribution of Tanimoto scores from the intersection and union distributions, and their correlation with one another, either determined empirically, or under a stochastic generative model of fingerprints.
<fig id="F3" position="float"><label>Fig. 3.</label><caption><p>Distribution of Tanimoto scores (red &#x02018;+&#x02019;) and their ratio-of-Gaussians approximations (blue lines). The Tanimoto distributions were sampled using empirical fingerprints for the ChemDB results, and randomly generated fingerprints for the binomial and multiple Bernoulli models. The hypergeometric/Gaussian distribution was calculated directly from Equation (<xref ref-type="disp-formula" rid="M10">10</xref>). The ratio-of-Gaussians model provides excellent approximations of the Tanimoto distributions.</p></caption><graphic xlink:href="btn187f3"/></fig>
<table-wrap id="T2" position="float"><label>Table 2.</label><caption><p>Empirical and model Tanimoto score distribution parameters</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="left" rowspan="1" colspan="1">Distribution</th><th align="left" rowspan="1" colspan="1"><bold>&#x003bc;</bold></th><th align="left" rowspan="1" colspan="1"><bold>&#x003c3;</bold></th><th align="left" rowspan="1" colspan="1"><bold>&#x003c1;</bold></th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Tanimoto (ChemDB)</td><td rowspan="1" colspan="1"><bold>0.17</bold></td><td rowspan="1" colspan="1"><bold>0.052</bold></td><td rowspan="1" colspan="1">0.82</td></tr><tr><td rowspan="1" colspan="1">Tanimoto (<italic>f</italic><sub><italic>T</italic></sub>(t)<sub><italic>ChemDB</italic></sub>)</td><td rowspan="1" colspan="1"><bold>0.16</bold></td><td rowspan="1" colspan="1"><bold>0.055</bold></td><td rowspan="1" colspan="1">0.82</td></tr><tr><td rowspan="1" colspan="1">Tanimoto (Binomial)</td><td rowspan="1" colspan="1">0.12</td><td rowspan="1" colspan="1">0.017</td><td rowspan="1" colspan="1">0.28</td></tr><tr><td rowspan="1" colspan="1">Tanimoto (Multiple Bernoulli)</td><td rowspan="1" colspan="1"><bold>0.18</bold></td><td rowspan="1" colspan="1">0.018</td><td rowspan="1" colspan="1">0.25</td></tr><tr><td rowspan="1" colspan="1">Tanimoto (Hypergeometric/Gaussian)</td><td rowspan="1" colspan="1">0.10</td><td rowspan="1" colspan="1"><bold>0.050</bold></td><td rowspan="1" colspan="1">0.90</td></tr></tbody></table><table-wrap-foot><fn><p>The parameters were determined from Gaussian fits to the distributions, except for the ratio-of-Gaussians parameters (<italic>f</italic><sub><italic>T</italic></sub>(<italic>t</italic>)<sub>ChemDB</sub>), which were determined directly from the analytical formula for <italic>f</italic><sub><italic>T</italic></sub>(<italic>t</italic>). The intersection and union correlations are also given. The ratio-of-Gaussians approximation gives accurate estimates of the empirical distribution parameters. With the empirical bit probabilities, the multiple Bernoulli model gives a good approximation of the empirical mean, but the distribution width is too small. Conversely, the use of a Gaussian to model the query and database fingerprints allows to the hypergeometric/Gaussian model to reproduce the empirical distribution width, though the distribution mean is smaller than the empirical value.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="SEC6.3"><title>6.3 Extreme value distributions</title><p>Once the distribution of Tanimoto scores is determined, either empirically from a database of molecules, or based upon a mathematical model, it is possible to assess the significance of a particular similarity score in relation to this distribution. One way to assess a score's significance is through its <italic>P</italic>-value, which can be calculated from the cumulative distribution of the maximum scores as <italic>p</italic>=1&#x02212;<italic>F</italic><sub>max</sub>(<italic>t</italic>). From the ratio-of-Gaussians approximation calculated from the fitted ChemDB parameters, the distributions of the maximum scores <italic>f</italic><sub>max</sub>(<italic>t</italic>) and their cumulative distributions <italic>F</italic><sub>max</sub>(<italic>t</italic>) were calculated for various database sizes <italic>D</italic> (<xref ref-type="fig" rid="F4">Fig. 4</xref>). For small database sizes (<italic>D</italic>&#x0003c;5000), the maximum scores lie in the 0.2&#x02013;0.4 interval. Upon further increase in <italic>D</italic>, the maximum score distribution widens, and becomes nearly uniform above <italic>t</italic>=0.4. Finally, for <italic>D</italic>&#x0003e;50000, <italic>f</italic><sub>max</sub>(<italic>t</italic>) gets pushed closer to <italic>t</italic>=1.0, and begins to concentrate around this upper score limit. The resulting cumulative distributions indicate that database size plays an important role in determining the <italic>P</italic>-value of a similarity score. For small databases, a large similarity score may result in a very small <italic>P</italic>-value, while for a large database, the same score may produce a much larger <italic>P</italic>-value.
<fig id="F4" position="float"><label>Fig. 4.</label><caption><p>Maximum and cumulative maximum Tanimoto score distributions derived from Equations (<xref ref-type="disp-formula" rid="M17">17</xref>) and (<xref ref-type="disp-formula" rid="M18">18</xref>) using the empirical ratio-of-Gaussian parameters for different database sizes <italic>D</italic> (red: <italic>D</italic>=100, green: <italic>D</italic>=1000, blue: <italic>D</italic>=5000, magenta: <italic>D</italic>=10000, cyan: <italic>D</italic>=50000, black: <italic>D</italic>=500000). As <italic>D</italic> increases for <italic>f</italic><sub>max</sub>(<italic>t</italic>), the distribution shifts from being concentrated around relatively low scores, to scores concentrated around 1.0. For small database sizes, the cumulative distributions <italic>F</italic><sub>max</sub>(<italic>t</italic>) quickly increase and saturate toward lower scores, while at larger databases sizes, the distributions remain small over most of the score range and rapidly increase as they approach 1.0.</p></caption><graphic xlink:href="btn187f4"/></fig>
</p><p>When investigating the distribution of maximum scores, another important question to consider is how many hits, above a given similarity threshold, one should expect on average. In <xref ref-type="table" rid="T3">Table 3</xref>, the percentage of molecules with similarity scores above a lower limit <italic>t</italic><sub>min</sub> are given, estimated using the score distribution predicted by the ratio-of-Gaussians model with the fitted ChemDB parameters. As the threshold increases, the number of expected hits rapidly falls off. The values in <xref ref-type="table" rid="T3">Table 3</xref> represent a first order approximation of the number of expected hits in the tails of the Tanimoto score distribution for an average query. However, potentially large deviations in these values are possible depending upon the size of the query <italic>A</italic>. More accurate estimates of the number of hits in the distribution tails may be obtained using the theory outlined in <xref ref-type="sec" rid="SEC4.3">Section 4.3</xref> for the distributions conditioned on <italic>A</italic> (results not shown).
<table-wrap id="T3" position="float"><label>Table 3.</label><caption><p>Percentages of molecules with similarity scores above <italic>t</italic><sub><italic>min</italic></sub> from the ratio-of-Gaussians approximation with the fitted ChemDB parameters</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="left" rowspan="1" colspan="1"><italic>t</italic><sub>min</sub></th><th align="left" rowspan="1" colspan="1">Gaussian ratio (%)</th><th align="left" rowspan="1" colspan="1">No. Hits (<italic>D</italic>=1 <italic>M</italic>)</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">0.4</td><td rowspan="1" colspan="1">0.033</td><td rowspan="1" colspan="1">330</td></tr><tr><td rowspan="1" colspan="1">0.5</td><td rowspan="1" colspan="1">0.015</td><td rowspan="1" colspan="1">150</td></tr><tr><td rowspan="1" colspan="1">0.6</td><td rowspan="1" colspan="1">0.010</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1">0.7</td><td rowspan="1" colspan="1">0.007</td><td rowspan="1" colspan="1">70</td></tr><tr><td rowspan="1" colspan="1">0.8</td><td rowspan="1" colspan="1">0.004</td><td rowspan="1" colspan="1">40</td></tr><tr><td rowspan="1" colspan="1">0.9</td><td rowspan="1" colspan="1">0.002</td><td rowspan="1" colspan="1">20</td></tr></tbody></table><table-wrap-foot><fn><p>The number of expected molecule hits is also shown for a database of size <italic>D</italic>=1<italic>M</italic>. These values provide a qualitative estimate of the number of hits expected for a typical query above the given Tanimoto thresholds.</p></fn></table-wrap-foot></table-wrap></p></sec></sec><sec sec-type="discussion" id="SEC7"><title>7 DISCUSSION AND CONCLUSIONS</title><p>We have presented a general mathematical framework, along with several stochastic models for chemical fingerprint, from which the distribution of similarity scores, and the extreme value distributions can be accurately predicted. As shown in <xref ref-type="fig" rid="F2">Figure 2</xref>, the intersection and union distributions are well described by Gaussians, both in the empirical case and for the fingerprint models. Using the Gaussian parameters and the correlation between the intersection and union distributions, the ratio-of-Gaussians model can be used to accurately predict the expected Tanimoto score distribution, illustrated by the good agreement between the Tanimoto and ratio-of-Gaussian distributions in <xref ref-type="fig" rid="F3">Figure 3</xref>. Once the Tanimoto distribution has been determined, an assessment of similarity score significance can be made using, for example, <italic>Z</italic>-scores or <italic>P</italic>-values.</p><p>It is important to note that several factors, including the choice of fingerprint features, compression method, and the size of the query and database fingerprints can influence the statistical properties of a particular similarity score distribution. For this reason, it is not possible to give concrete values characterizing these properties for general use, as they will depend upon the details of the chemical database system used. However, using ChemDB with path-based, lossy modulo-OR compressed fingerprints, we have observed several important trends in the resulting Tanimoto score distribution. First, scores are very small on average, approximately <italic>t</italic>=0.17, and the bulk of the distribution is located below <italic>t</italic>=0.4, which is more than four standard deviations away from the mean. As a result, Tanimoto scores as low as <italic>t</italic>=0.4 are much higher than average, and may be of potential interest. Second, for scores above <italic>t</italic>=0.4, one can expect on the order of 10<sup>2</sup> hits for a database of size 1 million. However, it should be noted that this estimate was obtained using query and database molecules both taken from ChemDB, and the estimate may vary widely for query molecules outside the region of chemical space covered by the database, or queries that are much smaller or larger than an average sized query. Finally, the size of the database has an important effect on the distributions of the maximum scores (<xref ref-type="fig" rid="F4">Fig. 4</xref>). As <italic>D</italic> increases, the maximum score distribution concentrates closer and closer to <italic>t</italic>=1.0, and for large databases containing several million compounds, it is highly likely to find a similarity score very close or equal to 1.0. It is also important to note that a Tanimoto score of 1.0 does not necessarily imply that the scored pair of molecules are the same. Aside from fingerprint compression, which can map two different uncompressed fingerprints onto the same compressed representation by chance, chirality and other types of atomic arrangements can also lead to two different molecules having the same fingerprint. This is a limitation of the path and tree features used, which can be insensitive to certain kinds of molecular symmetries.</p><p>To test the similarity score statistical framework in practice, several example molecules, including natural products (Tyrosol), drug compounds (Tamoxifen), and metabolites (deoxyuridine) were queried against a random subset of ChemDB containing 1M compounds (<xref ref-type="fig" rid="F5">Fig. 5</xref>). While the top scoring hits show a large degree of visual similarity to the queries as expected, the bottom hits also retain a certain degree of visual similarity and contain several common substructures. Also in line with the theoretical framework, the top hits have scores close to <italic>t</italic>=1.0, particularly for Tamoxifen and deoxyuridine, as predicted by the distribution of maximum scores <italic>f</italic><sub>max</sub>(<italic>t</italic>).
<fig id="F5" position="float"><label>Fig. 5.</label><caption><p>Example molecules queried against ChemDB. For each query, the given number of hits refers to the number of molecules with similarity scores above <italic>t</italic>=0.4. The top scoring hits are also shown along with the lowest scoring hits above <italic>t</italic>=0.4, and their corresponding <italic>Z</italic>-scores.</p></caption><graphic xlink:href="btn187f5"/></fig>
</p><p>While a detailed understanding of the similarity score distribution underlying a chemical database can be useful, even for individual queries performed by hand, such understanding becomes essential for large-scale, high-throughput, computational studies, where manual inspection of all the hits is not feasible. Such studies are becoming routine in the areas of metabolomics, chemical genomics, systems biology and drug screening/discovery. In these areas, understanding the statistical properties of chemical similarity scores should be vitally important for identifying new molecules of interest, building effective computational screening pipelines, and furthering our understanding chemical space.</p></sec></body><back><ack><title>ACKNOWLEDGEMENTS</title><p>Work supported by an NIH Biomedical Informatics Training grant (LM-07443-01) to PB and RB, and an NSF MRI grant (EIA-0321390) to PB. We would like also to acknowledge the OpenBabel project, OpenEye Scientific Software and ChemAxon for their free software academic licenses.</p><p><italic>Conflict of Interest</italic>: none declared.</p></ack><ref-list><title>REFERENCES</title><ref id="B1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ackley</surname><given-names>DH</given-names></name><etal/></person-group><article-title>A learning algorithm for Boltzmann machines</article-title><source>Cogn. Sci</source><year>1985</year><volume>9</volume><fpage>147</fpage><lpage>169</lpage></element-citation></ref><ref id="B2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altschul</surname><given-names>SF</given-names></name><etal/></person-group><article-title>Gapped blast and psiblast: a new generation of protein database search programs</article-title><source>Nucleic Acids Res</source><year>1997</year><volume>25</volume><fpage>3389</fpage><lpage>3402</lpage><pub-id pub-id-type="pmid">9254694</pub-id></element-citation></ref><ref id="B3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldi</surname><given-names>P</given-names></name><etal/></person-group><article-title>Lossless compression of chemical fingerprints using integer entropy codes improves storage and retrieval</article-title><source>J. Chem. Inform. Model</source><year>2007</year><volume>47</volume><fpage>2098</fpage><lpage>2109</lpage></element-citation></ref><ref id="B4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bender</surname><given-names>A</given-names></name><etal/></person-group><article-title>Similarity searching of chemical databases using atom environment descriptors (molprint 2d): Evaluation of performance</article-title><source>J. Chem. Inform. Model</source><year>2004</year><volume>44</volume><fpage>1708</fpage><lpage>1718</lpage></element-citation></ref><ref id="B5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohacek</surname><given-names>RS</given-names></name><etal/></person-group><article-title>The art and practice of tructure-based drug design: a molecular modelling perspective</article-title><source>Med. Res. Rev</source><year>1996</year><volume>16</volume><fpage>3</fpage><lpage>50</lpage><pub-id pub-id-type="pmid">8788213</pub-id></element-citation></ref><ref id="B6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cedilnik</surname><given-names>A</given-names></name><etal/></person-group><article-title>The distribution of the ratio of jointly normal variables</article-title><source>Metodoloski Zveki</source><year>2004</year><volume>1</volume><fpage>99</fpage><lpage>108</lpage></element-citation></ref><ref id="B7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><etal/></person-group><article-title>ChemDB: a public database of small molecules and related chemoinformatics resources</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>4133</fpage><lpage>4139</lpage><pub-id pub-id-type="pmid">16174682</pub-id></element-citation></ref><ref id="B8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><etal/></person-group><article-title>ChemDB update-full text search and virtual chemical space</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>2348</fpage><lpage>2351</lpage><pub-id pub-id-type="pmid">17599932</pub-id></element-citation></ref><ref id="B9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Coles</surname><given-names>S</given-names></name></person-group><source>An Introduction to Statistical Modeling of Extreme Values</source><year>2001</year><publisher-loc>London</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="B10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fligner</surname><given-names>MA</given-names></name><etal/></person-group><article-title>A modification of the Jaccard/Tanimoto similarity index for diverse selection of chemical compounds using binary strings</article-title><source>Technometrics</source><year>2002</year><volume>44</volume><fpage>110</fpage><lpage>119</lpage></element-citation></ref><ref id="B11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flower</surname><given-names>DR</given-names></name></person-group><article-title>On the properties of bit string-based measures of chemical similarity</article-title><source>J. Chem. Inform. Comput. Sci</source><year>1998</year><volume>38</volume><fpage>379</fpage><lpage>386</lpage></element-citation></ref><ref id="B12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>B</given-names></name></person-group><source>Graphical Models for Machine Learning and Digital Communicaiton</source><year>1998</year><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="B13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Galambos</surname><given-names>J</given-names></name></person-group><source>The Asymptotic Theory of Extreme Order Statistics</source><year>1978</year><publisher-loc>New York</publisher-loc><publisher-name>John Wiley</publisher-name></element-citation></ref><ref id="B14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassan</surname><given-names>M</given-names></name><etal/></person-group><article-title>Cheminformatics analysis and learning in a data pipelining environment</article-title><source>Mol. Divers</source><year>2006</year><volume>10</volume><fpage>283</fpage><lpage>299</lpage><pub-id pub-id-type="pmid">17031533</pub-id></element-citation></ref><ref id="B15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hert</surname><given-names>J</given-names></name><etal/></person-group><article-title>Comparison of topological descriptors for similarity-based virtual screening using multiple bioactive reference structures</article-title><source>Org. Biomol. Chem</source><year>2004</year><volume>2</volume><fpage>3256</fpage><lpage>3266</lpage><pub-id pub-id-type="pmid">15534703</pub-id></element-citation></ref><ref id="B16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinkley</surname><given-names>DV</given-names></name></person-group><article-title>On the ratio of two correlated normal random variables</article-title><source>Biometrika</source><year>1969</year><volume>56</volume><fpage>635</fpage><lpage>639</lpage></element-citation></ref><ref id="B17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holliday</surname><given-names>JD</given-names></name><etal/></person-group><article-title>Grouping of coefficients for the calculation of inter-molecular similarity and dissimilarity using 2d fragment bit-strings</article-title><source>Comb. Chem. High Throughput Screen</source><year>2002</year><volume>5</volume><fpage>155</fpage><lpage>166</lpage><pub-id pub-id-type="pmid">11966424</pub-id></element-citation></ref><ref id="B18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Irwin</surname><given-names>JJ</given-names></name><name><surname>Shoichet</surname><given-names>BK</given-names></name></person-group><article-title>ZINC&#x02013;a free database of commercially available compounds for virtual screening</article-title><source>J. Chem. Inform. Comput. Sci</source><year>2005</year><volume>45</volume><fpage>177</fpage><lpage>182</lpage></element-citation></ref><ref id="B19"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>James</surname><given-names>CA</given-names></name><etal/></person-group><source>Daylight Theory Manual</source><year>2004</year><comment>Available at <ext-link ext-link-type="uri" xlink:href="http://www.daylight.com/dayhtml/doc/theory/theory.toc.html">http://www.daylight.com/dayhtml/doc/theory/theory.toc.html</ext-link></comment></element-citation></ref><ref id="B20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Leach</surname><given-names>AR</given-names></name><name><surname>Gillet</surname><given-names>VJ</given-names></name></person-group><source>An Introduction to Chemoinformatics</source><year>2005</year><publisher-loc>Dordrecht, The Netherlands</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="B21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Leadbetter</surname><given-names>MR</given-names></name><etal/></person-group><source>Extremems and Related Properties of Random Sequences and Series</source><year>1983</year><publisher-loc>New York</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="B22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marsaglia</surname><given-names>G</given-names></name></person-group><article-title>Ratios of normal variables and rations of sums of uniform variables</article-title><source>J. Ameri. Stat. Assoc</source><year>1965</year><volume>60</volume><fpage>193</fpage><lpage>204</lpage></element-citation></ref><ref id="B23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pham-Gia</surname><given-names>T</given-names></name><etal/></person-group><article-title>Density of the ratio of two normal random variables and applications</article-title><source>Commun. Stat.-Theory Methods</source><year>2006</year><volume>35</volume><fpage>1569</fpage><lpage>1591</lpage></element-citation></ref><ref id="B24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouvray</surname><given-names>D</given-names></name></person-group><article-title>Definition and role of similarity concepts in the chemical and physical sciences</article-title><source>J. Chem. Inform. Comput. Sci</source><year>1992</year><volume>32</volume><fpage>580</fpage><lpage>586</lpage></element-citation></ref><ref id="B25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swamidass</surname><given-names>S</given-names></name><name><surname>Baldi</surname><given-names>P</given-names></name></person-group><article-title>Bounds and algorithms for exact searches of chemical fingerprints in linear and sub-linear time</article-title><source>J. Chem. Inform. Model</source><year>2007</year><volume>47</volume><fpage>302</fpage><lpage>317</lpage></element-citation></ref><ref id="B26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A</given-names></name></person-group><article-title>Features of similarity</article-title><source>Psychol. Rev</source><year>1977</year><volume>84</volume><fpage>327</fpage><lpage>352</lpage></element-citation></ref><ref id="B27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>L</given-names></name><etal/></person-group><article-title>Profile scaling increases the similarity search performance of molecular fingerprints containing numerical descriptors and structural keys</article-title><source>J. Chem. Inform. Comput. Sci</source><year>2003</year><volume>43</volume><fpage>1218</fpage><lpage>1225</lpage></element-citation></ref><ref id="B28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>L</given-names></name><etal/></person-group><article-title>Similarity search profiling reveals effects of fingerprint scaling in virtual screening</article-title><source>J. Chem. Inform. Comput. Sci</source><year>2004</year><volume>44</volume><fpage>2032</fpage><lpage>2039</lpage></element-citation></ref></ref-list></back></article>